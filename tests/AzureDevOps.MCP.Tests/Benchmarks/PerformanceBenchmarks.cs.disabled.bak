using System.Diagnostics;
using AzureDevOps.MCP.Services;
using AzureDevOps.MCP.Services.Core;
using AzureDevOps.MCP.Services.Infrastructure;
using AzureDevOps.MCP.Extensions;
using Microsoft.Extensions.Caching.Memory;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Microsoft.Extensions.Configuration;
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Running;

namespace AzureDevOps.MCP.Tests.Benchmarks;

[TestClass]
public class PerformanceBenchmarks
{
	ICacheService _cacheService = null!;
	IPerformanceService _performanceService = null!;

	[TestInitialize]
	public void Setup ()
	{
		var services = new ServiceCollection ();
		services.AddLogging ();
		services.AddMemoryCache ();

		var provider = services.BuildServiceProvider ();
		var memoryCache = provider.GetRequiredService<IMemoryCache> ();
		var cacheLogger = provider.GetRequiredService<ILogger<CacheService>> ();
		var perfLogger = provider.GetRequiredService<ILogger<PerformanceService>> ();

		_cacheService = new CacheService (memoryCache, cacheLogger);
		_performanceService = new PerformanceService (perfLogger);
	}

	[TestMethod]
	public async Task Benchmark_CacheService_SetAndGet_Performance ()
	{
		const int iterations = 1000;
		const string keyPrefix = "benchmark_key_";
		const string value = "benchmark_value_with_some_content_to_simulate_real_data";

		// Warmup
		for (int i = 0; i < 10; i++) {
			await _cacheService.SetAsync ($"warmup_{i}", value);
			await _cacheService.GetAsync<string> ($"warmup_{i}");
		}

		// Benchmark Set operations
		var setStopwatch = Stopwatch.StartNew ();
		for (int i = 0; i < iterations; i++) {
			await _cacheService.SetAsync ($"{keyPrefix}{i}", value);
		}
		setStopwatch.Stop ();

		// Benchmark Get operations
		var getStopwatch = Stopwatch.StartNew ();
		for (int i = 0; i < iterations; i++) {
			await _cacheService.GetAsync<string> ($"{keyPrefix}{i}");
		}
		getStopwatch.Stop ();

		// Assert performance expectations
		var setAvgMs = setStopwatch.ElapsedMilliseconds / (double)iterations;
		var getAvgMs = getStopwatch.ElapsedMilliseconds / (double)iterations;

		Console.WriteLine ($"Cache Set: {setAvgMs:F3}ms avg, {iterations / setStopwatch.Elapsed.TotalSeconds:F0} ops/sec");
		Console.WriteLine ($"Cache Get: {getAvgMs:F3}ms avg, {iterations / getStopwatch.Elapsed.TotalSeconds:F0} ops/sec");

		// Performance thresholds (adjust based on requirements)
		setAvgMs.Should ().BeLessThan (1.0, "Set operations should be fast");
		getAvgMs.Should ().BeLessThan (0.5, "Get operations should be very fast");
	}

	[TestMethod]
	public async Task Benchmark_PerformanceService_TrackingOverhead ()
	{
		const int iterations = 10000;

		// Benchmark without tracking
		var withoutTrackingStopwatch = Stopwatch.StartNew ();
		for (int i = 0; i < iterations; i++) {
			await SimulateWork (1); // 1ms work
		}
		withoutTrackingStopwatch.Stop ();

		// Benchmark with tracking
		var withTrackingStopwatch = Stopwatch.StartNew ();
		for (int i = 0; i < iterations; i++) {
			using var tracker = _performanceService.TrackOperation ("BenchmarkOperation");
			await SimulateWork (1); // 1ms work
		}
		withTrackingStopwatch.Stop ();

		var overhead = withTrackingStopwatch.ElapsedMilliseconds - withoutTrackingStopwatch.ElapsedMilliseconds;
		var overheadPerOp = overhead / (double)iterations;

		Console.WriteLine ($"Without tracking: {withoutTrackingStopwatch.ElapsedMilliseconds}ms total");
		Console.WriteLine ($"With tracking: {withTrackingStopwatch.ElapsedMilliseconds}ms total");
		Console.WriteLine ($"Overhead: {overhead}ms total, {overheadPerOp:F3}ms per operation");

		// Performance threshold: tracking overhead should be minimal
		overheadPerOp.Should ().BeLessThan (0.1, "Performance tracking overhead should be minimal");

		var metrics = await _performanceService.GetMetricsAsync ();
		metrics.TotalOperations.Should ().Be (iterations);
		metrics.Operations.Should ().ContainKey ("BenchmarkOperation");
	}

	[TestMethod]
	public async Task Benchmark_ConcurrentOperations ()
	{
		const int concurrentTasks = 50;
		const int operationsPerTask = 100;

		var tasks = new List<Task> ();

		var stopwatch = Stopwatch.StartNew ();

		for (int taskId = 0; taskId < concurrentTasks; taskId++) {
			var id = taskId; // Capture for closure
			tasks.Add (Task.Run (async () => {
				for (int op = 0; op < operationsPerTask; op++) {
					var key = $"concurrent_{id}_{op}";
					var value = $"value_{id}_{op}";

					using var tracker = _performanceService.TrackOperation ("ConcurrentOperation");
					await _cacheService.SetAsync (key, value);
					var retrieved = await _cacheService.GetAsync<string> (key);

					if (retrieved != value) {
						throw new InvalidOperationException ($"Cache consistency error: {key}");
					}
				}
			}));
		}

		await Task.WhenAll (tasks);
		stopwatch.Stop ();

		var totalOperations = concurrentTasks * operationsPerTask;
		var opsPerSecond = totalOperations / stopwatch.Elapsed.TotalSeconds;

		Console.WriteLine ($"Concurrent operations: {totalOperations} in {stopwatch.ElapsedMilliseconds}ms");
		Console.WriteLine ($"Throughput: {opsPerSecond:F0} operations/second");

		// Verify metrics consistency
		var metrics = await _performanceService.GetMetricsAsync ();
		metrics.Operations["ConcurrentOperation"].Count.Should ().Be (totalOperations);

		// Performance threshold
		opsPerSecond.Should ().BeGreaterThan (1000, "Should handle at least 1000 concurrent operations per second");
	}

	[TestMethod]
	public async Task Benchmark_MemoryUsage ()
	{
		const int dataItems = 10000;
		const string largeValue = new string ('X', 1000); // 1KB per item

		var initialMemory = GC.GetTotalMemory (true);

		// Add lots of data to cache
		for (int i = 0; i < dataItems; i++) {
			await _cacheService.SetAsync ($"memory_test_{i}", largeValue);
		}

		var afterCacheMemory = GC.GetTotalMemory (false);
		var cacheMemoryUsage = afterCacheMemory - initialMemory;

		// Clear cache
		_cacheService.Clear ();

		// Force garbage collection
		GC.Collect ();
		GC.WaitForPendingFinalizers ();
		GC.Collect ();

		var afterClearMemory = GC.GetTotalMemory (true);
		var memoryReclaimed = afterCacheMemory - afterClearMemory;

		Console.WriteLine ($"Initial memory: {initialMemory:N0} bytes");
		Console.WriteLine ($"After caching {dataItems} items: {afterCacheMemory:N0} bytes");
		Console.WriteLine ($"Cache memory usage: {cacheMemoryUsage:N0} bytes ({cacheMemoryUsage / 1024.0 / 1024.0:F2} MB)");
		Console.WriteLine ($"After clear: {afterClearMemory:N0} bytes");
		Console.WriteLine ($"Memory reclaimed: {memoryReclaimed:N0} bytes ({memoryReclaimed / (double)cacheMemoryUsage * 100:F1}%)");

		// Verify memory is reclaimed efficiently
		var reclaimPercentage = memoryReclaimed / (double)cacheMemoryUsage * 100;
		reclaimPercentage.Should ().BeGreaterThan (80, "Cache should release most of its memory when cleared");
	}

	static async Task SimulateWork (int milliseconds)
	{
		await Task.Delay (milliseconds);
	}
}

/// <summary>
/// BenchmarkDotNet benchmarks for core service operations.
/// Run with: dotnet run -c Release --project tests/AzureDevOps.MCP.Tests --filter Benchmark
/// </summary>
[MemoryDiagnoser]
[SimpleJob]
public class ServicePerformanceBenchmarks
{
	private IServiceProvider _serviceProvider = null!;
	private ICacheService _cacheService = null!;
	private IPerformanceService _performanceService = null!;

	[GlobalSetup]
	public void Setup()
	{
		var services = new ServiceCollection();
		
		// Add minimal configuration for benchmarks
		var configuration = new ConfigurationBuilder()
			.AddInMemoryCollection(new Dictionary<string, string?>
			{
				["AzureDevOps:Cache:DefaultExpirationMinutes"] = "5",
				["AzureDevOps:Cache:MaxItems"] = "1000"
			})
			.Build();

		// Add Azure DevOps services
		services.AddAzureDevOpsMcpServices(configuration);
		
		_serviceProvider = services.BuildServiceProvider();
		_cacheService = _serviceProvider.GetRequiredService<ICacheService>();
		_performanceService = _serviceProvider.GetRequiredService<IPerformanceService>();
	}

	[GlobalCleanup]
	public void Cleanup()
	{
		_serviceProvider?.Dispose();
	}

	[Benchmark]
	[Arguments(100)]
	[Arguments(1000)]
	[Arguments(10000)]
	public async Task CacheService_SetOperations(int itemCount)
	{
		var tasks = new List<Task>();
		
		for (int i = 0; i < itemCount; i++)
		{
			var key = $"benchmark_key_{i}";
			var value = $"benchmark_value_{i}";
			tasks.Add(_cacheService.SetAsync(key, value));
		}

		await Task.WhenAll(tasks);
	}

	[Benchmark]
	[Arguments(100)]
	[Arguments(1000)]
	[Arguments(10000)]
	public async Task CacheService_GetOperations(int itemCount)
	{
		// Setup: Add items to cache first
		for (int i = 0; i < itemCount; i++)
		{
			await _cacheService.SetAsync($"get_benchmark_key_{i}", $"value_{i}");
		}

		// Benchmark: Get operations
		var tasks = new List<Task>();
		
		for (int i = 0; i < itemCount; i++)
		{
			tasks.Add(_cacheService.GetAsync<string>($"get_benchmark_key_{i}"));
		}

		await Task.WhenAll(tasks);
	}

	[Benchmark]
	[Arguments(10)]
	[Arguments(50)]
	[Arguments(100)]
	public async Task PerformanceService_ConcurrentTracking(int concurrentOperations)
	{
		var tasks = new List<Task>();

		for (int i = 0; i < concurrentOperations; i++)
		{
			var operationId = i;
			tasks.Add(Task.Run(async () =>
			{
				await _performanceService.TrackOperationAsync(
					$"BenchmarkOperation_{operationId}",
					async () =>
					{
						await Task.Delay(1); // Simulate 1ms work
						return Task.CompletedTask;
					});
			}));
		}

		await Task.WhenAll(tasks);
	}

	[Benchmark]
	public async Task ServiceDecorator_OverheadMeasurement()
	{
		// This benchmark measures the overhead of the decorator pattern
		// by performing a simple operation through all decorator layers
		
		var projectService = _serviceProvider.GetRequiredService<IProjectService>();
		
		// This will go through: Authorization -> Performance -> Caching -> Core service
		// The core service will likely fail (no real Azure DevOps), but we measure the overhead
		try
		{
			await projectService.GetProjectsAsync();
		}
		catch
		{
			// Expected to fail in benchmark environment
		}
	}
}

/// <summary>
/// Memory allocation benchmarks for service operations.
/// </summary>
[MemoryDiagnoser]
[SimpleJob]
public class MemoryAllocationBenchmarks
{
	private ICacheService _cacheService = null!;

	[GlobalSetup]
	public void Setup()
	{
		var services = new ServiceCollection();
		services.AddMemoryCache();
		services.AddLogging();
		
		var provider = services.BuildServiceProvider();
		var memoryCache = provider.GetRequiredService<IMemoryCache>();
		var logger = provider.GetRequiredService<ILogger<CacheService>>();
		
		_cacheService = new CacheService(memoryCache, logger);
	}

	[Benchmark]
	public async Task SmallObject_CacheOperations()
	{
		var smallObject = new { Id = 1, Name = "Test" };
		
		await _cacheService.SetAsync("small_object", smallObject);
		await _cacheService.GetAsync<object>("small_object");
	}

	[Benchmark]
	public async Task LargeObject_CacheOperations()
	{
		var largeObject = new
		{
			Id = 1,
			Name = "Test",
			Description = new string('X', 1000), // 1KB string
			Data = Enumerable.Range(0, 100).ToList(), // List of 100 integers
			Timestamp = DateTime.UtcNow
		};
		
		await _cacheService.SetAsync("large_object", largeObject);
		await _cacheService.GetAsync<object>("large_object");
	}

	[Benchmark]
	[Arguments(10)]
	[Arguments(100)]
	[Arguments(1000)]
	public async Task BatchCacheOperations(int batchSize)
	{
		var tasks = new List<Task>();
		
		// Batch set operations
		for (int i = 0; i < batchSize; i++)
		{
			var obj = new { Id = i, Value = $"Value_{i}" };
			tasks.Add(_cacheService.SetAsync($"batch_key_{i}", obj));
		}
		
		await Task.WhenAll(tasks);
		tasks.Clear();
		
		// Batch get operations
		for (int i = 0; i < batchSize; i++)
		{
			tasks.Add(_cacheService.GetAsync<object>($"batch_key_{i}"));
		}
		
		await Task.WhenAll(tasks);
	}
}

/// <summary>
/// Stress test benchmarks for high-load scenarios.
/// </summary>
[SimpleJob]
public class StressTestBenchmarks
{
	private IServiceProvider _serviceProvider = null!;

	[GlobalSetup]
	public void Setup()
	{
		var services = new ServiceCollection();
		
		var configuration = new ConfigurationBuilder()
			.AddInMemoryCollection(new Dictionary<string, string?>
			{
				["AzureDevOps:Cache:DefaultExpirationMinutes"] = "1",
				["AzureDevOps:Cache:MaxItems"] = "10000"
			})
			.Build();

		services.AddAzureDevOpsMcpServices(configuration);
		_serviceProvider = services.BuildServiceProvider();
	}

	[GlobalCleanup]
	public void Cleanup()
	{
		_serviceProvider?.Dispose();
	}

	[Benchmark]
	[Arguments(1000, 10)] // 1000 operations, 10 concurrent tasks
	[Arguments(5000, 50)] // 5000 operations, 50 concurrent tasks
	public async Task HighConcurrency_CacheStressTest(int totalOperations, int concurrentTasks)
	{
		var cacheService = _serviceProvider.GetRequiredService<ICacheService>();
		var operationsPerTask = totalOperations / concurrentTasks;
		
		var tasks = new List<Task>();
		
		for (int taskId = 0; taskId < concurrentTasks; taskId++)
		{
			var id = taskId;
			tasks.Add(Task.Run(async () =>
			{
				for (int op = 0; op < operationsPerTask; op++)
				{
					var key = $"stress_key_{id}_{op}";
					var value = new { 
						TaskId = id, 
						Operation = op, 
						Timestamp = DateTime.UtcNow,
						Data = new string('A', 100) // 100 char string
					};
					
					await cacheService.SetAsync(key, value);
					
					// 50% chance to retrieve the item immediately
					if (op % 2 == 0)
					{
						await cacheService.GetAsync<object>(key);
					}
				}
			}));
		}
		
		await Task.WhenAll(tasks);
	}

	[Benchmark]
	public async Task MemoryPressure_LargeDataStressTest()
	{
		var cacheService = _serviceProvider.GetRequiredService<ICacheService>();
		var largeDataSize = 10000; // 10KB per item
		var itemCount = 100;
		
		for (int i = 0; i < itemCount; i++)
		{
			var largeData = new
			{
				Id = i,
				LargeString = new string('X', largeDataSize),
				Timestamp = DateTime.UtcNow,
				Metadata = Enumerable.Range(0, 100).Select(x => $"Meta_{x}").ToList()
			};
			
			await cacheService.SetAsync($"large_data_{i}", largeData);
		}
		
		// Trigger some retrievals
		for (int i = 0; i < itemCount / 2; i++)
		{
			await cacheService.GetAsync<object>($"large_data_{i}");
		}
	}
}